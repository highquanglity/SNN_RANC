{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bed_21.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNUqfnHInVV-"
      },
      "outputs": [],
      "source": [
        "cd \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/phuongtrau/SNN_TeaLearning_Training.git"
      ],
      "metadata": {
        "id": "lYVlsjWunmcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/SNN_TeaLearning_Training/tealayers/tealayer1.0/tealayers/3_class\""
      ],
      "metadata": {
        "id": "d80KsAOwnvrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install bitstring\n",
        "!pip install keras==2.3.0"
      ],
      "metadata": {
        "id": "jmf3paQ1nwfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PYTHON**"
      ],
      "metadata": {
        "id": "BYAV6PffHDde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import thư viện**"
      ],
      "metadata": {
        "id": "oydd8x1uHO3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import operator\n",
        "import functools\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras import Model\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Activation, Input, Lambda, Concatenate,Average\n",
        "from keras.datasets import mnist,fashion_mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import sys\n",
        "sys.path.append(\"../../../../rancutils/rancutils\")\n",
        "import os\n",
        "\n",
        "from teaconversion import create_cores,create_packets,get_connections_and_biases\n",
        "from packet import Packet\n",
        "sys.path.append(\"../\")\n",
        "# from tea import Tea\n",
        "from additivepooling import AdditivePooling\n",
        "import helper\n",
        "from tea import Tea\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lE5b2LVopxg",
        "outputId": "9ae39518-eb98-464c-84f8-ddc33da265e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za6WBhAEHfD_"
      },
      "source": [
        "**Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_i_data = helper.load_exp_i_short(\"../../dataset/experiment-i\")"
      ],
      "metadata": {
        "id": "Ca5fpEN6t0Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {\"Base\":exp_i_data}\n",
        "train_data = helper.Mat_Dataset(datasets,[\"Base\"],[\"S1\",\"S2\",\"S3\",\"S4\",\"S5\",\"S6\",\"S7\",\"S8\",\"S9\"])\n",
        "test_data = helper.Mat_Dataset(datasets,[\"Base\"],[\"S10\",\"S11\",\"S12\",\"S13\"])"
      ],
      "metadata": {
        "id": "zxYNdSXApOO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HfZqZLiLejx"
      },
      "source": [
        "**Tiền xử lý data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_data.samples)):\n",
        "    train_data.samples[i] = cv2.equalizeHist(train_data.samples[i])\n",
        "for i in range(len(test_data.samples)):\n",
        "    test_data.samples[i] = cv2.equalizeHist(test_data.samples[i])"
      ],
      "metadata": {
        "id": "eGNLD3TLplpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data.samples.astype('float32')\n",
        "x_test = test_data.samples.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(train_data.labels, 3)\n",
        "y_test = to_categorical(test_data.labels, 3)\n",
        "\n",
        "random.seed(2)\n",
        "(x_train,y_train) = shuffle(x_train,y_train)\n",
        "(x_test,y_test) = shuffle(x_test,y_test)"
      ],
      "metadata": {
        "id": "5pPdDQ_Xpqvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTr4uabxH6sW"
      },
      "source": [
        "**Training model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define per-fold score containers\n",
        "for i in range(len(train_data.samples)):\n",
        "    train_data.samples[i] = cv2.equalizeHist(train_data.samples[i])\n",
        "\n",
        "x_train = train_data.samples.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "\n",
        "y_train = to_categorical(train_data.labels, 3)\n",
        "\n",
        "random.seed(2)\n",
        "(x_train,y_train) = shuffle(x_train,y_train)\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "kfold = KFold(n_splits = 2, shuffle = False)\n",
        "fold_no = 1\n",
        "for train,test in kfold.split(x_train,y_train):\n",
        "      \n",
        "  inputs = Input(shape=(64, 32,))\n",
        "  flattened_inputs = Flatten()(inputs)\n",
        "\n",
        "  x1_1  = Lambda(lambda x : x[:,     :256 ])(flattened_inputs)\n",
        "\n",
        "  x1_2  = Lambda(lambda x : x[:, 119 : 375 ])(flattened_inputs)\n",
        "\n",
        "  x1_3  = Lambda(lambda x : x[:, 238 :494 ])(flattened_inputs)\n",
        "\n",
        "  x1_4  = Lambda(lambda x : x[:, 357 : 613])(flattened_inputs)\n",
        "\n",
        "  x1_5  = Lambda(lambda x : x[:, 476:732])(flattened_inputs)\n",
        "\n",
        "  x1_6  = Lambda(lambda x : x[:, 595:851])(flattened_inputs)\n",
        "\n",
        "  x1_7  = Lambda(lambda x : x[:, 714:970])(flattened_inputs)\n",
        "\n",
        "  x1_8  = Lambda(lambda x : x[:, 833:1089])(flattened_inputs)\n",
        "\n",
        "  x1_9  = Lambda(lambda x : x[:, 952:1208])(flattened_inputs)\n",
        "\n",
        "  x1_10  = Lambda(lambda x : x[:, 1071:1327])(flattened_inputs)\n",
        "\n",
        "  x1_11  = Lambda(lambda x : x[:, 1190:1446])(flattened_inputs)\n",
        "\n",
        "  x1_12  = Lambda(lambda x : x[:, 1309:1565])(flattened_inputs)\n",
        "\n",
        "  x1_13  = Lambda(lambda x : x[:, 1428:1684])(flattened_inputs)\n",
        "\n",
        "  x1_14  = Lambda(lambda x : x[:, 1547:1803])(flattened_inputs)\n",
        "\n",
        "  x1_15  = Lambda(lambda x : x[:, 1666:1922])(flattened_inputs)\n",
        "\n",
        "  x1_16  = Lambda(lambda x : x[:, 1785:2041])(flattened_inputs)\n",
        "\n",
        "  x1_1  = Tea(64, name='tea_1_1')(x1_1)\n",
        "  x1_2  = Tea(64, name='tea_1_2')(x1_2)\n",
        "  x1_3  = Tea(64, name='tea_1_3')(x1_3)\n",
        "  x1_4  = Tea(64, name='tea_1_4')(x1_4)\n",
        "  x1_5  = Tea(64, name='tea_1_5')(x1_5)\n",
        "  x1_6  = Tea(64, name='tea_1_6')(x1_6)\n",
        "  x1_7  = Tea(64, name='tea_1_7')(x1_7)\n",
        "  x1_8  = Tea(64, name='tea_1_8')(x1_8)\n",
        "  x1_9  = Tea(64, name='tea_1_9')(x1_9)\n",
        "  x1_10  = Tea(64, name='tea_1_10')(x1_10)\n",
        "  x1_11  = Tea(64, name='tea_1_11')(x1_11)\n",
        "  x1_12  = Tea(64, name='tea_1_12')(x1_12)\n",
        "  x1_13  = Tea(64, name='tea_1_13')(x1_13)\n",
        "  x1_14  = Tea(64, name='tea_1_14')(x1_14)\n",
        "  x1_15  = Tea(64, name='tea_1_15')(x1_15)\n",
        "  x1_16  = Tea(64, name='tea_1_16')(x1_16)\n",
        "\n",
        "  x2_1 = Concatenate(axis=1)([x1_1,x1_2,x1_3,x1_4])\n",
        "  x2_2 = Concatenate(axis=1)([x1_5,x1_6,x1_7,x1_8])\n",
        "  x2_3 = Concatenate(axis=1)([x1_9,x1_10,x1_11,x1_12])\n",
        "  x2_4 = Concatenate(axis=1)([x1_13,x1_14,x1_15,x1_16])\n",
        "\n",
        "  x2_1 = Tea(64, name='tea_2_1')(x2_1)\n",
        "  x2_2 = Tea(64, name='tea_2_2')(x2_2)\n",
        "  x2_3 = Tea(64, name='tea_2_3')(x2_3)\n",
        "  x2_4 = Tea(64, name='tea_2_4')(x2_4)\n",
        "\n",
        "  x_out = Concatenate(axis=1)([x2_1,x2_2,x2_3,x2_4])\n",
        "  x_out = Tea(255, name='tea_3')(x_out)\n",
        "  x_out = AdditivePooling(3)(x_out)\n",
        "  \n",
        "  predictions = Activation('softmax')(x_out)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.0005),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  model.fit(x_train[train], y_train[train],\n",
        "            batch_size=64,\n",
        "            epochs=30,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\n",
        "  score = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
        "  \n",
        "  acc_per_fold.append(score[1] * 100)\n",
        "  loss_per_fold.append(score[0])\n",
        "  \n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1]*100,'%')\n",
        "\n",
        "  fold_no = fold_no + 1\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "DL7vOJg9pxXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BZqzWX5IBh4"
      },
      "source": [
        "**Generate network**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/SNN_TeaLearning_Training/tealayers/tealayer1.0/tealayers/3_class\""
      ],
      "metadata": {
        "id": "P_L17HXowdrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f163d3ba-a6d2-43bf-f7fa-9476a640530f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SNN_TeaLearning_Training/tealayers/tealayer1.0/tealayers/3_class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from output_bus import OutputBus\n",
        "from serialization import save as sim_save\n",
        "from emulation import write_cores\n",
        "\n",
        "x_test_flat = x_test.reshape((5219, 2048))\n",
        "partitioned_packets = []\n",
        "\n",
        "# Số lượng ảnh cần test (max 5219 ảnh)\n",
        "num_test_samples = 10\n",
        "\n",
        "# Tạo các core bằng hàm create_cores(), sử dụng 3 layer, sử dụng absolute reset mode: neuron_reset_type=0\n",
        "cores_sim = create_cores(model, 3, neuron_reset_type=0) \n",
        "# Partition the packets into groups as they will be fed into each of the input cores\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, :256])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 119:375])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 238:494])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 357:613])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 476:732])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 595:851])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 714:970])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 833:1089])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 952:1208])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1071:1327])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1190:1446])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1309:1565])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1428:1684])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1547:1803])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1666:1922])\n",
        "partitioned_packets.append(x_test_flat[:num_test_samples, 1785:2041])\n",
        "# Tạo packet bằng hàm create_packets()\n",
        "packets_sim = create_packets(partitioned_packets)\n",
        "# Tạo output_bus bằng hàm OutputBus(coordinate, num_outputs)\n",
        "output_bus_sim = OutputBus((0, 3), num_outputs=255)\n",
        "\n",
        "# Đây chính là file đầu vào cho giả lập kiến trúc RANC bằng code C++\n",
        "sim_save(\"/content/input_config.json\", cores_sim, packets_sim, output_bus_sim, indent=2)\n",
        "\n",
        "# Lưu lại đầu ra của tensorflow predictions và correct labels để tý làm cross validation\n",
        "predict = model.predict(x_test[:num_test_samples,:])\n",
        "idx = []\n",
        "for i in predict:\n",
        "  idx.append(np.argmax(i))\n",
        "test_predictions = to_categorical(idx)\n",
        "np.save(\"/content/output_tf_preds.txt\", test_predictions)\n",
        "np.save(\"/content/output_correct_preds.txt\", y_test[:num_test_samples,:])"
      ],
      "metadata": {
        "id": "Dm6OcKDMwfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lưu file mem**"
      ],
      "metadata": {
        "id": "wx6tZ5Q-CP4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from emulation import output_for_streaming, output_for_testbench"
      ],
      "metadata": {
        "id": "vTqpolFkA3gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_for_streaming(cores_sim,max_xy=(16,3),output_path=\"/content/21_cores_mem\")"
      ],
      "metadata": {
        "id": "n3ojiKXPCbGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/21_cores_mem.zip /content/21_cores_mem"
      ],
      "metadata": {
        "id": "CRr4H69RIY_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/21_cores_mem.zip\")"
      ],
      "metadata": {
        "id": "Y8kSJmDbIbJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6f9a921e-1e1e-4520-eaba-e421f07fabe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3615f91a-619f-478c-b29c-a60b5fb62257\", \"21_cores_mem.zip\", 124041)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lưu đầu vào, đầu ra chuẩn**"
      ],
      "metadata": {
        "id": "84do3a7sEtZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_for_testbench(packets_sim,\n",
        "                         y_test[:num_test_samples,:],\n",
        "                         output_path='/content/',\n",
        "                         input_filename='tb_input.txt',\n",
        "                         correct_filename='tb_correct.txt',\n",
        "                         num_inputs_filename='tb_num_inputs.txt',\n",
        "                         num_outputs_filename='tb_num_outputs.txt',\n",
        "                         max_packet_xy=(512, 512),\n",
        "                         num_axons=256,\n",
        "                         num_ticks=16,\n",
        "                         num_outputs=256)"
      ],
      "metadata": {
        "id": "Fqf-bIi3EmLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7iP2MulazDV"
      },
      "source": [
        "# **C++**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59mywRAGsLK2"
      },
      "source": [
        "**Compile code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRkhibSsbOqL",
        "outputId": "4e5a9d7d-d503-429d-88ca-0b01cff51e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyVAzbOrZG_y"
      },
      "outputs": [],
      "source": [
        "!unzip \"simulator.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al1m8tDOba2r",
        "outputId": "cc309cf3-2cab-4e61-afa2-8f1b90db8b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simulator\n"
          ]
        }
      ],
      "source": [
        "cd \"./simulator/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPRlcKqWb_Ef"
      },
      "outputs": [],
      "source": [
        "!mkdir build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jpMr4FCbbUo",
        "outputId": "573eb74b-8e2f-413f-f62e-c47825ea6461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/simulator/build\n"
          ]
        }
      ],
      "source": [
        "cd build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_IM4WGXcBbB"
      },
      "outputs": [],
      "source": [
        "!cmake \"..\"\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVd3VwY9sO_K"
      },
      "source": [
        "**Chạy code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ddsl-uhsdWK"
      },
      "source": [
        "Muốn chạy với x ảnh thì số tick là x + 3, do trễ 3 tick từ 3 layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3vAU8dIdZfz"
      },
      "outputs": [],
      "source": [
        "!/content/simulator/build/ranc_sim -i /content/input_config.json -o /content/simulator_output.txt -c /content/simulator/config.json 13 -t trace.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg-JWGbjt0Z6"
      },
      "source": [
        "# **So sánh**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcq-tsjIsTQJ"
      },
      "source": [
        "Trước khi so sánh, xóa 3 dòng đầu của \"simulator_output.txt\", do mạng có 3 layer nên sẽ bị trễ 3 tick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg218K1leQkO",
        "outputId": "87910354-ebd9-4876-ea92-ad3d62641211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SNN_TeaLearning_Training/rancutils/rancutils\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/SNN_TeaLearning_Training/rancutils/rancutils\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-CgdLUdaop",
        "outputId": "08fbf272-d8d7-423d-85a6-2ffa58942a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow output matches simulator output exactly!\n",
            "Testing accuracy against known class labels is 100.0%\n"
          ]
        }
      ],
      "source": [
        "from simulator import collect_classifications_from_simulator\n",
        "tf_output = np.load(\"/content/output_tf_preds.txt\"+\".npy\")\n",
        "correct_output = np.load(\"/content/output_correct_preds.txt\"+\".npy\")\n",
        "simulator_output = collect_classifications_from_simulator(\"/content/simulator_output.txt\", num_classes=3)\n",
        "\n",
        "tf_output_flat = np.array([0] * tf_output.shape[0])\n",
        "for i in range(tf_output.shape[0]):\n",
        "    output_i = tf_output[i, :]\n",
        "    decision = np.where(output_i == max(output_i))[0]\n",
        "    if len(decision) > 1:\n",
        "        decision = decision[0]\n",
        "    tf_output_flat[i] = decision\n",
        "tf_output = tf_output_flat\n",
        "    \n",
        "correct_output_flat = np.array([0] * correct_output.shape[0])\n",
        "for i in range(correct_output.shape[0]):\n",
        "    output_i = correct_output[i, :]\n",
        "    decision = np.where(output_i == max(output_i))[0]\n",
        "    if len(decision) > 1:\n",
        "        decision = decision[0]\n",
        "    correct_output_flat[i] = decision\n",
        "correct_output = correct_output_flat\n",
        "\n",
        "if all(tf_output == simulator_output):\n",
        "    print(\"Tensorflow output matches simulator output exactly!\")\n",
        "    print(f\"Testing accuracy against known class labels is {(len(np.where(tf_output == correct_output[:len(tf_output)])[0]) / len(tf_output)) * 100}%\")\n",
        "else:\n",
        "    print(\"There are differences between Tensorflow and the simulator...\")\n",
        "    print(f\"Differences are in indices {np.where(tf_output != simulator_output)}\")\n",
        "    print(f\"Tensorflow thought the classes were {tf_output[np.where(tf_output != simulator_output)]}\")\n",
        "    print(f\"The simulator thought the classes were {simulator_output[np.where(tf_output != simulator_output)]}\")\n",
        "    print(f\"The correct classes were {correct_output[np.where(tf_output != simulator_output)]}\")"
      ]
    }
  ]
}